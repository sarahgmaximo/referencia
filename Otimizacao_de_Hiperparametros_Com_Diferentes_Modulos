
Exemplo de uso do Optuna para otimizar um modelo XGBoost

import optuna
import xgboost as xgb
from sklearn.datasets import load_boston
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Carregar dados de exemplo
boston = load_boston()
X, y = boston.data, boston.target

# Dividir os dados em treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Função de objetivo para otimização com Optuna
def objective(trial):
    # Definir hiperparâmetros para otimização
    params = {
        'objective': 'reg:squarederror',
        'n_estimators': trial.suggest_int('n_estimators', 50, 200),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'subsample': trial.suggest_uniform('subsample', 0.1, 1.0),
        'gamma': trial.suggest_uniform('gamma', 0, 1)
    }

    # Treinar modelo XGBoost com hiperparâmetros otimizados
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)

    # Realizar previsões no conjunto de teste
    y_pred = model.predict(X_test)

    # Calcular o erro médio quadrático como métrica de avaliação
    mse = mean_squared_error(y_test, y_pred)

    return mse



# Criação e otimização do estudo com Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)
Exemplo de uso do Hyperopt para otimizar um modelo XGBoost
Pitão

Copiar código
import hyperopt
from hyperopt import fmin, tpe, hp
import xgboost as xgb
from sklearn.datasets import load_boston
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Carregar dados de exemplo
boston = load_boston()
X, y = boston.data, boston.target

# Dividir os dados em treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Função de objetivo para otimização com Hyperopt
def objective(params):
    # Treinar modelo XGBoost com hiperparâmetros otimizados
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)

    # Realizar previsões no conjunto de teste
    y_pred = model.predict(X_test)

    # Calcular o erro médio quadrático como métrica de avaliação
    mse = mean_squared_error(y_test, y_pred)

    return mse

# Espaço de busca para os hiperparâmetros
